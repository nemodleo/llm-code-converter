import numpy as np
from typing import Any
from pathlib import Path
from .reference_store import ReferenceExample
from .embedder import CodeEmbedder
from .embedder import get_embedding_model


class CaseRetriever:
    """RAG ê¸°ë°˜ ë ˆí¼ëŸ°ìŠ¤ ì˜ˆì œ ê²€ìƒ‰ê¸°"""
    
    def __init__(self, 
                 embedder: CodeEmbedder = None,
                 embedding_data: dict[str, Any] = None,
                 data_dir: str = "data"):
        
        self.data_dir = Path(data_dir)
        self.embedder = embedder
        self.embedding_data = embedding_data
        
        if self.embedder is None:
            self.embedder = CodeEmbedder(model_name=get_embedding_model())
    
    def load_embedding_data(self, filename: str = "map_to_vo_embeddings"):
        """ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
        self.embedding_data = self.embedder.load_embeddings(filename)
        print(f"âœ… Loaded {len(self.embedding_data['references'])} reference embeddings")
    
    def retrieve_similar_examples(self, 
                                query_line: str,
                                context_before: list[str] = None,
                                context_after: list[str] = None,
                                top_k: int = 5,
                                min_similarity: float = 0.1) -> list[tuple[ReferenceExample, float]]:
        """
        ìœ ì‚¬í•œ ì˜ˆì œ ê²€ìƒ‰
        
        Args:
            query_line: ë³€í™˜í•  ì¿¼ë¦¬ ë¼ì¸
            context_before: ì´ì „ ì»¨í…ìŠ¤íŠ¸ ë¼ì¸ë“¤
            context_after: ì´í›„ ì»¨í…ìŠ¤íŠ¸ ë¼ì¸ë“¤  
            top_k: ë°˜í™˜í•  ì˜ˆì œ ìˆ˜
            min_similarity: ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
            
        Returns:
            (ReferenceExample, similarity_score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        
        if self.embedding_data is None:
            raise ValueError("Embedding data not loaded. Call load_embedding_data() first.")
        
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        use_context = self.embedding_data.get('use_context', True)
        query_embedding = self.embedder.embed_query(
            query_line, 
            context_before, 
            context_after, 
            use_context=use_context
        )
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        reference_embeddings = self.embedding_data['embeddings']
        similarities = self.embedder.compute_similarity(query_embedding, reference_embeddings)
        
        # ìƒìœ„ kê°œ ì„ íƒ
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            similarity = similarities[idx]
            if similarity >= min_similarity:
                reference = self.embedding_data['references'][idx]
                results.append((reference, float(similarity)))
        
        return results
    
    def retrieve_with_filters(self,
                            query_line: str,
                            context_before: list[str] = None,
                            context_after: list[str] = None,
                            task_type: str = None,
                            top_k: int = 5,
                            min_similarity: float = 0.1) -> list[tuple[ReferenceExample, float]]:
        """
        í•„í„°ë§ê³¼ í•¨ê»˜ ìœ ì‚¬í•œ ì˜ˆì œ ê²€ìƒ‰
        
        Args:
            task_type: íŠ¹ì • íƒœìŠ¤í¬ íƒ€ì…ìœ¼ë¡œ í•„í„°ë§
        """
        
        # ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜í–‰
        all_results = self.retrieve_similar_examples(
            query_line, context_before, context_after, 
            top_k=top_k*2,  # í•„í„°ë§ì„ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
            min_similarity=min_similarity
        )
        
        # íƒœìŠ¤í¬ íƒ€ì… í•„í„°ë§
        if task_type:
            filtered_results = [
                (ref, sim) for ref, sim in all_results 
                if ref.task_type == task_type
            ]
        else:
            filtered_results = all_results
        
        # ìƒìœ„ kê°œë§Œ ë°˜í™˜
        return filtered_results[:top_k]
    
    def explain_retrieval(self, 
                         query_line: str,
                         retrieved_examples: list[tuple[ReferenceExample, float]],
                         show_details: bool = True) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ ì„¤ëª…"""
        
        explanation = f"ğŸ” Query: '{query_line.strip()}'\n"
        explanation += f"ğŸ“Š Retrieved {len(retrieved_examples)} similar examples:\n\n"
        
        for i, (ref, similarity) in enumerate(retrieved_examples, 1):
            explanation += f"[{i}] Similarity: {similarity:.3f}\n"
            explanation += f"    Input:  '{ref.input_line.strip()}'\n"
            explanation += f"    Output: '{ref.output_line.strip()}'\n"
            
            if show_details and ref.context_before:
                explanation += f"    Context: {' | '.join(ref.context_before[-1:])}\n"
            
            explanation += "\n"
        
        return explanation
    
    def get_statistics(self) -> dict[str, Any]:
        """ê²€ìƒ‰ê¸° í†µê³„ ì •ë³´"""
        if self.embedding_data is None:
            return {"error": "No embedding data loaded"}
        
        references = self.embedding_data['references']
        
        stats = {
            "total_references": len(references),
            "model_name": self.embedding_data.get('model_name', 'unknown'),
            "use_context": self.embedding_data.get('use_context', False),
            "task_types": {}
        }
        
        # íƒœìŠ¤í¬ íƒ€ì…ë³„ í†µê³„
        for ref in references:
            task_type = ref.task_type
            if task_type not in stats["task_types"]:
                stats["task_types"][task_type] = 0
            stats["task_types"][task_type] += 1
        
        return stats
    
    def get_prompt(self, query_line: str) -> str | None:
        """ì¿¼ë¦¬ ë¼ì¸ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return self.explain_retrieval(query_line, self.retrieve_similar_examples(query_line, top_k=3))


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_retriever_from_files(input_file: str, output_file: str, 
                               embedding_filename: str = "map_to_vo_embeddings") -> CaseRetriever:
    """íŒŒì¼ë¡œë¶€í„° ê²€ìƒ‰ê¸° ìƒì„±"""
    from .reference_store import ReferenceStore
    from .embedder import get_recommended_model_for_java
    
    # 1. ë ˆí¼ëŸ°ìŠ¤ ìƒì„±
    store = ReferenceStore()
    references = store.create_references_from_files(input_file, output_file)
    store.save_references(references, "temp_references")
    
    # 2. ì„ë² ë”© ìƒì„±
    embedder = CodeEmbedder(model_name=get_recommended_model_for_java())
    embedding_data = embedder.embed_reference_examples(references, use_context=True)
    embedder.save_embeddings(embedding_data, embedding_filename)
    
    # 3. ê²€ìƒ‰ê¸° ìƒì„±
    retriever = CaseRetriever(embedder=embedder, embedding_data=embedding_data)
    
    return retriever


def quick_search(query_line: str, 
                context_before: list[str] = None,
                top_k: int = 3) -> list[tuple[ReferenceExample, float]]:
    """ë¹ ë¥¸ ê²€ìƒ‰ (ê¸°ë³¸ ì„ë² ë”© ì‚¬ìš©)"""
    retriever = CaseRetriever()
    
    try:
        retriever.load_embedding_data()
        return retriever.retrieve_similar_examples(
            query_line, context_before, top_k=top_k
        )
    except Exception as e:
        print(f"âŒ Quick search failed: {e}")
        return []


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    retriever = CaseRetriever()
    
    try:
        retriever.load_embedding_data()
        stats = retriever.get_statistics()
        print("ğŸ“Š Retriever Statistics:")
        for key, value in stats.items():
            print(f"   {key}: {value}")
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        # test_query = "public class TestService {"
        # test_query = "public Arraylist<Map> selectHAHAHAExecution(Map doc)  throws ElException {"
        test_query = "public void deleteEmpXDA(Map doc) throws Exception {"
        results = retriever.retrieve_similar_examples(test_query, top_k=3)
        
        if results:
            print("\n" + retriever.explain_retrieval(test_query, results))
        else:
            print("âŒ No similar examples found")
            
    except FileNotFoundError:
        print("âŒ No embedding data found. Please run embedder.py first to create embeddings.")