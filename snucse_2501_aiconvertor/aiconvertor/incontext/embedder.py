import pickle
from typing import Any
from pathlib import Path
import numpy as np
from sentence_transformers import SentenceTransformer
from .reference_store import ReferenceExample


class CodeEmbedder:
    """ì½”ë“œ ì„ë² ë”© ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 model_name: str = "microsoft/codebert-base", 
                 data_dir: str = "data"):
        """
        ì½”ë“œ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_name: ì„ë² ë”© ëª¨ë¸ëª… (ì½”ë“œì— íŠ¹í™”ëœ ëª¨ë¸)
                      - microsoft/codebert-base: ì½”ë“œ ì´í•´ì— íŠ¹í™”
                      - microsoft/graphcodebert-base: ì½”ë“œ êµ¬ì¡° ì´í•´
                      - sentence-transformers/all-MiniLM-L6-v2: ë²”ìš© (ë¹ ë¦„)
        """
        self.model_name = model_name
        self.data_dir = Path(data_dir)
        self.db_dir = self.data_dir / "db"
        self.db_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ”„ Loading embedding model: {model_name}")
        self.model = SentenceTransformer(model_name)
        
        print(f"âœ… Embedding model loaded: {self.model_name}")
    
    def preprocess_code_line(self, line: str, context_before: list[str] = None, 
                           context_after: list[str] = None) -> str:
        """ì½”ë“œ ë¼ì¸ ì „ì²˜ë¦¬"""
        # ì•ë’¤ ê³µë°± ì œê±°
        line = line.strip()
        
        # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í•¨ê»˜ í¬í•¨ (ì„ íƒì )
        if context_before or context_after:
            context_text = ""
            if context_before:
                context_text += " ".join([l.strip() for l in context_before[-2:]])  # ìµœê·¼ 2ì¤„ë§Œ
            context_text += f" {line} "
            if context_after:
                context_text += " ".join([l.strip() for l in context_after[:2]])   # ë‹¤ìŒ 2ì¤„ë§Œ
            return context_text.strip()
        
        return line
    
    def embed_reference_examples(self, references: list[ReferenceExample], 
                               use_context: bool = True) -> dict[str, Any]:
        """ë ˆí¼ëŸ°ìŠ¤ ì˜ˆì œë“¤ì˜ ì„ë² ë”© ìƒì„±"""
        
        print(f"ğŸ”„ Creating embeddings for {len(references)} reference examples")
        
        # ì…ë ¥ ë¼ì¸ë“¤ ì „ì²˜ë¦¬
        input_texts = []
        for ref in references:
            if use_context:
                text = self.preprocess_code_line(
                    ref.input_line, 
                    ref.context_before, 
                    ref.context_after
                )
            else:
                text = self.preprocess_code_line(ref.input_line)
            input_texts.append(text)
        
        # ì„ë² ë”© ìƒì„±
        embeddings = self.model.encode(input_texts, show_progress_bar=True)
        
        # ê²°ê³¼ êµ¬ì¡°í™”
        embedding_data = {
            'embeddings': embeddings,
            'references': references,
            'model_name': self.model_name,
            'use_context': use_context,
            'input_texts': input_texts  # ë””ë²„ê¹…ìš©
        }
        
        return embedding_data
    
    def embed_query(self, query_line: str, context_before: list[str] = None, 
                   context_after: list[str] = None, use_context: bool = True) -> np.ndarray:
        """ì¿¼ë¦¬ ë¼ì¸ì˜ ì„ë² ë”© ìƒì„±"""
        
        if use_context:
            text = self.preprocess_code_line(query_line, context_before, context_after)
        else:
            text = self.preprocess_code_line(query_line)
        
        embedding = self.model.encode([text])
        return embedding[0]
    
    def save_embeddings(self, embedding_data: dict[str, Any], filename: str):
        """ì„ë² ë”© ë°ì´í„° ì €ì¥"""
        filepath = self.db_dir / f"{filename}.pkl"
        
        with open(filepath, 'wb') as f:
            pickle.dump(embedding_data, f)
        
        print(f"âœ… Embeddings saved to {filepath}")
        return filepath
    
    def load_embeddings(self, filename: str) -> dict[str, Any]:
        """ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
        filepath = self.db_dir / f"{filename}.pkl"
        
        if not filepath.exists():
            raise FileNotFoundError(f"Embeddings file not found: {filepath}")
        
        with open(filepath, 'rb') as f:
            embedding_data = pickle.load(f)
        
        print(f"âœ… Embeddings loaded from {filepath}")
        return embedding_data
    
    def compute_similarity(self, query_embedding: np.ndarray, 
                          reference_embeddings: np.ndarray) -> np.ndarray:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        from sklearn.metrics.pairwise import cosine_similarity
        
        query_embedding = query_embedding.reshape(1, -1)
        similarities = cosine_similarity(query_embedding, reference_embeddings)[0]
        return similarities


def get_embedding_model(code: int = 0):
    """Java ì½”ë“œì— ì í•©í•œ ì„ë² ë”© ëª¨ë¸ ë°˜í™˜"""
    models = [
        "microsoft/codebert-base",           # ì½”ë“œ ì „ìš©, ì •í™•ë„ ë†’ìŒ
        "microsoft/graphcodebert-base",      # ì½”ë“œ êµ¬ì¡° ì´í•´, ë” ì •í™•
        "sentence-transformers/all-MiniLM-L6-v2",  # ë²”ìš©, ë¹ ë¦„
        "BAAI/bge-small-en-v1.5"            # ìµœì‹  ì„ë² ë”© ëª¨ë¸, ì„±ëŠ¥ ì¢‹ìŒ
    ]

    return models[code]


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    from .reference_store import ReferenceStore
    
    # ë ˆí¼ëŸ°ìŠ¤ ë¡œë“œ
    store = ReferenceStore()
    try:
        references = store.load_references("map_to_vo_samples")
    except FileNotFoundError:
        print("Creating sample references first...")
        references = store.create_sample_references()
    
    if references:
        # ì„ë² ë”© ìƒì„±
        recommended_model = get_embedding_model()
        embedder = CodeEmbedder(model_name=recommended_model)
        
        embedding_data = embedder.embed_reference_examples(references, use_context=False)
        embedder.save_embeddings(embedding_data, "map_to_vo_embeddings")
        
        print(f"âœ… Created embeddings for {len(references)} examples")
    else:
        print("âŒ No references found")